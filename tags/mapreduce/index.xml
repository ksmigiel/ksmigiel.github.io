<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Mapreduce on </title>
    <link>http://ksmigiel.com/tags/mapreduce/</link>
    <description>Recent content in Mapreduce on </description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Fri, 23 Jan 2015 18:16:13 +0100</lastBuildDate>
    <atom:link href="http://ksmigiel.com/tags/mapreduce/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>MapReduce - wstęp</title>
      <link>http://ksmigiel.com/2015/01/map-reduce</link>
      <pubDate>Fri, 23 Jan 2015 18:16:13 +0100</pubDate>
      
      <guid>http://ksmigiel.com/2015/01/map-reduce</guid>
      <description>

&lt;p&gt;Zapewne słyszeliście o &lt;strong&gt;MapReduce&lt;/strong&gt;, a jeśli nie, to teraz macie okazję poczytać. &lt;strong&gt;MapReduce&lt;/strong&gt; jest frameworkiem służącym do przetwarzania dużych zbiorów danych w sposób zrównoleglony. Ostatnimi czasy stał się bardzo popularny dzięki platformom takim jak &lt;a href=&#34;http://hadoop.apache.org&#34;&gt;Hadoop&lt;/a&gt; (o nim w kolejnym poście) czy &lt;a href=&#34;https://spark.apache.org&#34;&gt;Spark&lt;/a&gt;. Wykorzystywany jest wszędzie tam, gdzie dane liczy się w terabajtach. Duże firmy produkują dużo danych, więc znajduje on zastosowanie np. w Google czy Spotify.&lt;/p&gt;

&lt;h2 id=&#34;funkcyjnie:d6a86094d7ff3310f4dae7e5d0b58f2e&#34;&gt;Funkcyjnie&lt;/h2&gt;

&lt;p&gt;Na początku chciałem wspomnieć o dwóch ważnych rzeczach: &lt;code&gt;map()&lt;/code&gt; i &lt;code&gt;reduce()&lt;/code&gt;. Te dwie funkcje, które są elementami języków funkcyjnych (choć np. C# ma swoje odpowiedniki w LINQ: &lt;code&gt;Select()&lt;/code&gt; i &lt;code&gt;Aggregate()&lt;/code&gt;) działają w analogiczny sposób do MapReduce, tyle że na kolekcjach. Tak więc nazwa nie wzięła się znikąd.&lt;/p&gt;

&lt;h4 id=&#34;f-35:d6a86094d7ff3310f4dae7e5d0b58f2e&#34;&gt;F&amp;#35;&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;map()&lt;/code&gt; aplikuje funkcję dla każdego elementu z kolekcji:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-fsharp&#34;&gt;let sample = [1; 2; 3; 4; 5]
// Dodamy do każdego elementu listy &amp;quot;2&amp;quot;
List.map (fun x -&amp;gt; x + 2) sample
(* val it : int list = [3; 4; 5; 6; 7] *)
// lub bardziej funkcyjnie przy pomocy operatora &amp;quot;|&amp;gt;&amp;quot;
sample |&amp;gt; List.map (fun x -&amp;gt; x + 2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;reduce()&lt;/code&gt; natomiast jak się można domyślić: redukuje naszą kolekcję przy użyciu akumulatora przekazując wynik do następnego wywołania:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-fsharp&#34;&gt;// Zredukujemy naszą listę obliczając sumę ze wszystkich jej elementów
// a i b są sąsiadami
sample |&amp;gt; List.reduce (fun a b -&amp;gt; a + b)
(* val it : int = 15 *)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;c-35:d6a86094d7ff3310f4dae7e5d0b58f2e&#34;&gt;C&amp;#35;&lt;/h4&gt;

&lt;p&gt;I analogicznie przy użyciu LINQ&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-csharp&#34;&gt;var sample = new List&amp;lt;int&amp;gt;() {1, 2, 3, 4, 5};
sample.Select(x =&amp;gt; x + 2);
sample.Aggregate((a, b) =&amp;gt; a + b);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Operacje te prezentują prosty workflow jaki przeprowadza się na danych i w wersji rozszerzonej jest on wykorzystywany w MapReduce.&lt;/p&gt;

&lt;h2 id=&#34;map-reduce-mapreduce:d6a86094d7ff3310f4dae7e5d0b58f2e&#34;&gt;map() + reduce() -&amp;gt; MapReduce&lt;/h2&gt;

&lt;p&gt;Wprowadźmy kilka pojęć: węzeł &lt;strong&gt;(node)&lt;/strong&gt; to jeden z wielu komputerów biorących udział w tym całym zamieszaniu. Grupa takich komputerów o podobnej do siebie konfiguracji, będących w tej samej sieci nazywa się klastrem &lt;strong&gt;(cluster)&lt;/strong&gt;. To powinno wystarczyć do zrozumienia zasady działania MapReduce, choć ludzie zaznajomieni z tematem prawdopodobnie zamkną przeglądarkę z powodu takiej trywializacji :]&lt;/p&gt;

&lt;p&gt;Proces zazwyczaj odbywa się w 3 etapach: 2 tytułowe i jeden pomocniczy pomiędzy nimi:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Map&lt;/strong&gt; - na tym etapie każdy węzeł preparuje dane (np. usuwanie zbędnych rekordów, klasyfikacja poprzez dodanie kluczy itp.)&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Shuffle&lt;/strong&gt; - dane są tutaj sortowane i w takich grupach przydzielane do odpowiednich węzłów&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reduce&lt;/strong&gt; - następuje agregacja danych na podstawie klucza - oczywiście w sposób równoległy&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Tak naprawdę każdy z nas (developerów) nie raz w życiu coś zmapredusił. Bo jeśli sprowadzimy ten proces z chmury i skomplikowanej topologii do pojedynczej bazy danych, to okaże się, że ten cały MapReduce to w rzeczywistości można napisać w SQLu:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select id, sum(price)
from products
group by id
order by id
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Wynik takiego zapytania może być również skutkiem całego procesu MapReduce. I dopóki ilość danych i czas w jakim zapytanie się wykonuje mieszczą się w granicach wymagań biznesu, to wszystko ok! Problem zaczyna się wtedy, gdy wydajność maleje, bo instancje serwerów SQL nie radzą sobie z przetwarzaniem coraz szybciej i ciągle napływających danych. Dlatego głównie ze względu na kwestię wydajności wprowadza się paralelność, co klasyczną analizę danych wybija na wyższy poziom zaawansowania.&lt;/p&gt;

&lt;p&gt;Dane mogą teraz zostać przetworzone szybciej. Coś, co kiedyś trwało, lub ze względu na ograniczenia mocy obliczeniowej było prawie niemożliwe, dziś za pomocą chmury i tego typu technologii pozwala niejako na nowo odkrywać algorytmy uczenia maszynowego, data-miningu. A w jaki sposób to zostanie zaprezentowane.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>