<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Audio on </title>
    <link>http://ksmigiel.com/tags/audio/</link>
    <description>Recent content in Audio on </description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Wed, 18 Nov 2015 17:26:38 +0100</lastBuildDate>
    <atom:link href="http://ksmigiel.com/tags/audio/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Kulisy DevTalka cz. 2</title>
      <link>http://ksmigiel.com/2015/11/devtalk-cz2</link>
      <pubDate>Wed, 18 Nov 2015 17:26:38 +0100</pubDate>
      
      <guid>http://ksmigiel.com/2015/11/devtalk-cz2</guid>
      <description>

&lt;p&gt;Dzisiaj przedstawię proces powstawania odcinka DevTalk&amp;rsquo;a od strony audio-technicznej. Nie zabraknie obrazków i orientalnych pojęć, więc każdy znajdzie coś dla siebie - nudy nie bedzię :)&lt;/p&gt;

&lt;h2 id=&#34;przygotowanie-projektu:ee57e4abed1f49f2ac13a466738529d0&#34;&gt;Przygotowanie projektu&lt;/h2&gt;

&lt;p&gt;Pierwsze co robię przed przystąpieniem do jakiejkolwiek pracy nad nowym odcinkiem DevTalk&amp;rsquo;a jest przygotowanie projektu:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;opisuję ścieżki (&lt;em&gt;ang. tracks&lt;/em&gt;) i koloruję je, żebym wiedział co jest czym.&lt;/li&gt;
&lt;li&gt;synchronizuję - rozkładam je odpowiednio w czasie, odtwarzając przy tym naturalny przebieg rozmowy (rozmowa prowadzona przez Skype, jednakże ścieżki są zgrywane osobno). Do tego dochodzi umieszczenie takich elementów jak &lt;strong&gt;intro&lt;/strong&gt;, &lt;strong&gt;outro&lt;/strong&gt; i &lt;strong&gt;jingle&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&#34;http://ksmigiel.com/images/devtalk/01.jpg&#34;&gt;&lt;img src=&#34;http://ksmigiel.com/images/devtalk/01.jpg&#34; alt=&#34;01&#34; /&gt;
&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;normalizacja:ee57e4abed1f49f2ac13a466738529d0&#34;&gt;Normalizacja&lt;/h2&gt;

&lt;p&gt;Teraz następuje bardzo ważny krok nazywany &lt;strong&gt;normalizacją&lt;/strong&gt;. Jego wynik będzie wypływał na produkcję przez cały okres pracy, aż po render, dlatego warto poświęcić temu elementowi więcej uwagi.&lt;/p&gt;

&lt;p&gt;Normalizacja polega na &amp;ldquo;unormalnianiu&amp;rdquo; nagrania w zakresie jego głośności i dynamiki, w odniesieniu do reszty materiału dźwiękowego. Na chwilę obecną nasz projekt składa się z czterech plików i ścieżek, gdzie skala problemu nie jest duża. W przypadku projektów muzycznych, w których skład wchodzą 32+ ścieżki jest to już jednak znaczący problem.&lt;/p&gt;

&lt;p&gt;Tak więc naszym celem jest ustandaryzowanie materiału, który dostaliśmy z zewnątrz. Dokonać tego możemy m.in stosując:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://doughnutmag.com/tutorials/music-production/daw-automation/&#34;&gt;automatyzację&lt;/a&gt; i obwiednie (&lt;em&gt;ang. envelopes&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;kompresję sygnału audio&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;automatyzacja:ee57e4abed1f49f2ac13a466738529d0&#34;&gt;Automatyzacja&lt;/h3&gt;

&lt;p&gt;Polega na zmianie w czasie pewnych parametrów sygnału (głośność, panorama lub inny dowolny parametr mapowany z &lt;a href=&#34;https://en.wikipedia.org/wiki/Virtual_Studio_Technology&#34;&gt;efektu VST&lt;/a&gt;).
Krzywą można dowolnie modelować, co pozwala na precyzyjne manipulowanie wspomnianymi parametrami w przeciwieństwie do kompresji, która działa &amp;ldquo;automatycznie&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://ksmigiel.com/images/devtalk/02.jpg&#34;&gt;&lt;img src=&#34;http://ksmigiel.com/images/devtalk/02.jpg&#34; alt=&#34;02&#34; /&gt;
&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;kompresja:ee57e4abed1f49f2ac13a466738529d0&#34;&gt;Kompresja&lt;/h3&gt;

&lt;p&gt;Kompresor automatycznie zmniejsza dynamikę fragmentu, którego głośność przekracza ustaloną z góry granicę. Najprostszy kompresor będzie charakteryzował się kilkoma parametrami:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;próg (&lt;em&gt;ang. treshold&lt;/em&gt;) - czyli poziom, poniżej którego sygnał pozostanie bez zmian, a powyżej zostanie przekształcony w zadany przez nas sposób&lt;/li&gt;
&lt;li&gt;współczynnik kompresji (&lt;em&gt;ang. ratio&lt;/em&gt;) - określa stosunek pomiędzy sygnałem bazowym a wtórnym&lt;/li&gt;
&lt;li&gt;atak (&lt;em&gt;ang. attack&lt;/em&gt;) - podawany w milisekundach czas, po którym kompresor powinien się &amp;ldquo;załączyć&amp;rdquo;&lt;/li&gt;
&lt;li&gt;uwolnienie (&lt;em&gt;ang. release&lt;/em&gt;) - podwawany w milisekundach czas, po którym kompresor przestaje działać&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://pic002.cnblogs.com/images/2012/381603/2012030610395272.jpg&#34; alt=&#34;compressor&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;Zatem przy użyciu kompresora możemy elementy &amp;ldquo;wystające&amp;rdquo;, głośniejsze niż reszta, automatycznie zredukować do wspólnego poziomu. Dziać się to może w czasie rzeczywistym, kiedy efekt zostanie wpięty do ścieżki, lub możemy wyrenderować nowy plik z nałożonymi już efektami.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://ksmigiel.com/images/devtalk/04.jpg&#34;&gt;&lt;img src=&#34;http://ksmigiel.com/images/devtalk/04.jpg&#34; alt=&#34;04&#34; /&gt;
&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;punkt-odniesienia:ee57e4abed1f49f2ac13a466738529d0&#34;&gt;Punkt odniesienia&lt;/h3&gt;

&lt;p&gt;Podczas normalizacji należy monitorować sygnał i sprawdzać, czy poziomy rzeczywiście są już wyrównane i czy nie pojawia się gdzieś tzw. &amp;ldquo;przester&amp;rdquo; (czyli przekroczenie magicznej granicy 0dB). Osobiście dbam o to, aby sygnał z każdej ścieżki osobno oscylował w granicach -12dB RMS (jest to jednostka uśredniona) oraz aby &amp;ldquo;peak&amp;rdquo;, czyli najgłośniejszy element, nie przekraczał -6dB.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://ksmigiel.com/images/devtalk/03.jpg&#34;&gt;&lt;img src=&#34;http://ksmigiel.com/images/devtalk/03.jpg&#34; alt=&#34;03&#34; /&gt;
&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Ciekawych dlaczego 0dB w świecie cyfrowym jest sygnałem maksymalnym zapraszam do poczytania wytłumaczenia na &lt;a href=&#34;http://sound.stackexchange.com/questions/25529/what-is-0-db-in-digital-audio&#34;&gt;stackexchange&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;edycja:ee57e4abed1f49f2ac13a466738529d0&#34;&gt;Edycja&lt;/h2&gt;

&lt;p&gt;Następnym krokiem będzie edycja sygnału audio. Mając przygotowany w poprzednich krokach materiał możemy przystąpić do jego edycji. W moim przypadku proces ten wygląda najczęściej w ten sposób:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;odszumienie nagrań (dobrze żeby zrobic to przed kompresją) - używając wtyczki &lt;strong&gt;ReaFir (FFT EQ + Dynamic Processor)&lt;/strong&gt; wystarczy pobrać próbkę szumu z sygnału&lt;/li&gt;
&lt;li&gt;equalizacja - za pomocą korektora graficznego zbędne pasma wycinam (high-pass filter), niektóre podbijam, aby końcowo uzyskać spójne i naturalne brzmienie całego mixu (jak i każdej ścieżek z osobna)&lt;/li&gt;
&lt;li&gt;cięcie - usuwanie drobnych pomyłek, przerw, oddechów, mlasknięć itp. itd., czyli pozbywanie się wszystkiego czego nie powinno być w ostatecznej wersji odcinka&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;mastering:ee57e4abed1f49f2ac13a466738529d0&#34;&gt;Mastering&lt;/h2&gt;

&lt;p&gt;Na ten moment odcinek jest już prawie gotowy. Jeśli mix potrzebuje jakichkolwiek zmian, to powinny się one odbywać jedynie w ujęciu globalnym, tj. na ścieżce głównej. Zazwyczaj jest to drobna korekcja EQ, lekka kompresja, raczej nic znaczącego, a jednak :) Ostatnim elementem tego audio-łańcuchu jest &lt;strong&gt;limiter&lt;/strong&gt;, który nasz mix wyrówna do ustalonego poziomu bliskiemu ~0dB, aby brzmiał tak samo głośno jak inne audio, podcasty, spotifaje itd. Potem zostaje render do wybranego przez nas formatu i gotowy produkt można publikować i czekać na lajki.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://ksmigiel.com/images/devtalk/05.jpg&#34;&gt;&lt;img src=&#34;http://ksmigiel.com/images/devtalk/05.jpg&#34; alt=&#34;05&#34; /&gt;
&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://doughnutmag.com/tutorials/music-production/daw-automation/&#34;&gt;http://doughnutmag.com/tutorials/music-production/daw-automation/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Virtual_Studio_Technology&#34;&gt;https://en.wikipedia.org/wiki/Virtual_Studio_Technology&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://sound.stackexchange.com/questions/25529/what-is-0-db-in-digital-audio&#34;&gt;http://sound.stackexchange.com/questions/25529/what-is-0-db-in-digital-audio&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Kulisy DevTalka cz. 1</title>
      <link>http://ksmigiel.com/2015/09/devtalk-cz1</link>
      <pubDate>Fri, 25 Sep 2015 17:26:38 +0200</pubDate>
      
      <guid>http://ksmigiel.com/2015/09/devtalk-cz1</guid>
      <description>

&lt;p&gt;Tak jak obiecywałem w poprzednim poście - nadszedł moment na podsumowanie ubiegłego roku podcastowego. Z perspektywy czasu żałuję, że nie prowadziłem szczegółowych statystyk (chociażby takich jak sumaryczny czas spędzony w edytorze audio), ale postaram się to jakoś poglądowo wyestymować :).&lt;/p&gt;

&lt;p&gt;W części pierwszej opiszę sprzęt z jakiego korzystałem z krótkim opisem co to jest (szczególnie dla czytelników niezaznajomionych z branżą pro-audio).
W części drugiej postaram się krótko, lecz treściwie przedstawić proces produkcji odcinka podcasta (załadowanie ścieżek, wyrównanie poziomów głośności i normalizacja, efekty - (odszumianie, equalizacja, kompresja), edycja, mastering i render).&lt;/p&gt;

&lt;h2 id=&#34;hardware:dce4ce542c9f7a851fd046a02392be71&#34;&gt;Hardware&lt;/h2&gt;

&lt;p&gt;Zdążyłem się już pochwalić nowym sprzętem, a drugi raz pochwalić się nie zaszkodzi. Jest to typowy sprzęt przeznaczony do &lt;em&gt;home-recordingu&lt;/em&gt;, co wcale nie musi kojarzyć się z amatorszczyzną. Ze względu na dobre parametry techniczne i stosunkowo dobry stosunek jakości przetworników cyfrowych do ceny, wprawne ucho wyprodukuje płytę CD, udźwiękowienie filmu w żaden sposób nie odbiegające od branżowych standardów (profesjonalnych nagrań).&lt;/p&gt;

&lt;h3 id=&#34;odsłuch:dce4ce542c9f7a851fd046a02392be71&#34;&gt;Odsłuch&lt;/h3&gt;

&lt;p&gt;Za odsłuch służą mi monitory bliskiego pola: &lt;strong&gt;M-Audio BX5 D2&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://zapp1.staticworld.net/reviews/graphics/products/uploaded/maudio_bx5_d2s_speaker_system_1147635_g1.jpg&#34; alt=&#34;M-Audio BX5 D2&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;Są to monitory aktywne i nie potrzebują osobnego wzmacniacza. Studyjne monitory odsłuchowe wyróżnia spośród innego sprzętu audio charakterystyka częstotliwościowa, która w tym wypadku powinna być jak najbardziej liniowa. Pozwala ona na odsłuch w brzmieniu jak najbardziej zbliżonym do rzeczywistego (źródła dźwięku), tj. bez żadnego podbicia basu, wycięcia środka czy &amp;ldquo;wysokich&amp;rdquo; górek. Dzięki temu tak przygotowany materiał - na &amp;ldquo;surowych&amp;rdquo; głośnikach - powinien zabrzmieć dobrze w dowolnym zestawie Hi-Fi czy iPod&amp;rsquo;ie. Oczywiście nie jest to jedyny warunek jaki trzeba spełnić aby nasz materiał był &amp;ldquo;pro&amp;rdquo;, ale o tym za chwilę.&lt;/p&gt;

&lt;h3 id=&#34;interfejs:dce4ce542c9f7a851fd046a02392be71&#34;&gt;Interfejs&lt;/h3&gt;

&lt;p&gt;Na upratego monitory można podłączyć do komputera bez interfejsu (skręcając kable od biedy), ale to właśnie on odgrywa kluczową rolę jeśli chodzi o jakość dźwięku. Porządny przetwornik C/A (cyfrowo-analogowy) pozwala odtwarzać oraz nagrywać muzykę zapisaną w wysokiej &lt;a href=&#34;https://en.wikipedia.org/wiki/Audio_bit_depth&#34;&gt;rozdzielczości&lt;/a&gt; (np. 24-bit), czyli technicznie zawierającą więcej informacji (bitów) przesłanych/odebranych na sekundę. Jest to nic innego jak próba reprezentacji sygnału analogowego w formie cyfrowej. Przekształcenie to nazywamy &lt;a href=&#34;http://livesound.pl/tutoriale/kursy/4011-technika-cyfrowa-przetwarzanie-analogowo-cyfrowe-kwantowanie&#34;&gt;&lt;strong&gt;kwantyzacją&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://documentation.apple.com/en/finalcutpro/usermanual/Art/L01/L0108_BitGraph.png&#34; alt=&#34;quantization&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;Wracając do tematu: do pracy używam interfejsu audio USB: &lt;strong&gt;M-Audio M-Track MKII&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.muzykaitechnologia.pl/website/var/tmp/image-thumbnails/30101/thumb__auto_793e482fec1c54dd5c5708c057c0e7cc/m-track-mkii--3.jpeg&#34; alt=&#34;m-audio m-track mk2&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;Dołączone sterowniki &lt;a href=&#34;https://en.wikipedia.org/wiki/Audio_Stream_Input/Output&#34;&gt;ASIO&lt;/a&gt; umożliwiają uzyskanie niskiej latencji (bliskiej zeru), dzięki czemu opóźnienia między sprzętem &amp;lt;-&amp;gt; oprogramowaniem są prawie całkowicie wyeliminowane.
Intefrejs ten posiada też wysokiej jakości wejścia mikrofonowe i instrumentalne. Daje to nieograniczone możliwości związane z nagrywaniem sygnału dźwiękowego, który potem ma zostać sklejony w całość (w przeciwieństwie do nagrywania na tzw. &lt;em&gt;&amp;ldquo;setkę&amp;rdquo;&lt;/em&gt;, gdzie każdy muzyk zajmuje osobny kanał i cała kapela nagrywa na żywca). Za często z tej możliwości nie korzystam, ponieważ wszystkie potrzebne ścieżki do odcinka czekają na mnie na GDrive. Jak w końcu umebluję pokój po przeprowadzce na to małe studyjko, to może coś nagram i się podzielę :)&lt;/p&gt;

&lt;h2 id=&#34;software:dce4ce542c9f7a851fd046a02392be71&#34;&gt;Software&lt;/h2&gt;

&lt;p&gt;Obecnie na rynku jest masa edytorów audio. Od prostych i darmowych (&lt;a href=&#34;http://audacityteam.org/&#34;&gt;Audacity&lt;/a&gt;) po bardzo zaawansowane kombajny takie jak: &lt;a href=&#34;http://www.avid.com/US/products/family/pro-tools/&#34;&gt;Pro Tools&lt;/a&gt;, &lt;a href=&#34;http://www.steinberg.net/en/home.html&#34;&gt;Cubase&lt;/a&gt; czy &lt;a href=&#34;https://www.ableton.com/&#34;&gt;Ableton&lt;/a&gt;, które określane są mianem &lt;strong&gt;DAW&lt;/strong&gt; (&lt;em&gt;ang. Digital Audio Workstation&lt;/em&gt;). Z którego narzędzia korzysta producent, to kwestia budżetu, przyzwyczajenia oraz &amp;ldquo;religijności&amp;rdquo; (tak, fan-boy&amp;rsquo;ie każdej technologii są wszędzie!). Ja po paru próbach (udanych bądź mniej) ostatecznie wybrałem swoje ulubione narzędzie pracy, którym jest &lt;a href=&#34;http://www.reaper.fm/&#34;&gt;&lt;strong&gt;Reaper&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;reaper:dce4ce542c9f7a851fd046a02392be71&#34;&gt;Reaper&lt;/h3&gt;

&lt;div style=&#34;text-align: center&#34;&gt;
&lt;img src=&#34;https://lh3.googleusercontent.com/-mtompVfMRoU/VNgzXSQUQDI/AAAAAAAAQvo/KD7l2ZHJFqM/s256-no/Cockos%2BREAPER.png&#34; /&gt;
&lt;/div&gt;

&lt;p&gt;Relatywnie tani z potężnymi możliwościami edytor niesamowicie przypadł mi do gustu. Praktycznie podczas każdej edycji odcinka podcasta uczę się czegoś nowego, wymyślam coraz to nowe makra, które automatyzują moją pracę i póki co nie zamieniłbym się na żaden inny edytor :). W następnym poście napiszę o nim więcej.&lt;/p&gt;

&lt;h2 id=&#34;óho:dce4ce542c9f7a851fd046a02392be71&#34;&gt;Óho&lt;/h2&gt;

&lt;p&gt;Najważniejszym elementem jakiegokolwiek studia jest &lt;strong&gt;ucho&lt;/strong&gt; (a nawet dwa). Bez zmysłu muzycznego (i oczywiście sprawnego ucha), nawet z pomocą najlepszego sprzętu i najdroższego programu nie będziemy w stanie dorównać poziomowi profesjonalnym nagrań. W tym wypadku jak w każdej innej branży, a szczególnie naszej - programistycznej - tylko ciężka praca i ciągła praktyka przyniesie wymierne efekty, bo narzędzia to tylko narzędzia.
A ja ciąglę praktykuję i mam nadzieję, że z przyjemnością słucha wam się każdego odcinka &lt;a href=&#34;http://www.devtalk.pl&#34;&gt;DevTalk&amp;rsquo;a&lt;/a&gt; :)&lt;/p&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Audio_bit_depth&#34;&gt;https://en.wikipedia.org/wiki/Audio_bit_depth&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://livesound.pl/tutoriale/kursy/4011-technika-cyfrowa-przetwarzanie-analogowo-cyfrowe-kwantowanie&#34;&gt;http://livesound.pl/tutoriale/kursy/4011-technika-cyfrowa-przetwarzanie-analogowo-cyfrowe-kwantowanie&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Audio_Stream_Input/Output&#34;&gt;https://en.wikipedia.org/wiki/Audio_Stream_Input/Output&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.reaper.fm/&#34;&gt;http://www.reaper.fm/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.devtalk.pl&#34;&gt;http://www.devtalk.pl&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
  </channel>
</rss>